{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is meant to be a toy network coupled with a very simple text processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# pandas and numpy for dataframes and array manipulations\n",
    "# tqdm as a progress\n",
    "# matplotlib for plotting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# usual PyTorch imports for tensor manipulations, neural networks and data processings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import some sklearn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# import keras tokenizing utilities \n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "# import tensorboardX in case we want to log metrics to tensorboard (requires tensorflow installed - optional)\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from graphviz import Digraph\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load train and test data and separate the target in another variable\n",
    "\n",
    "X_train = pd.read_csv('./data/train.csv')\n",
    "X_test = pd.read_csv('./data/test.csv')\n",
    "Y = X_train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define some keras tokenization parameters\n",
    "# NUM_WORDS: the maximum number of tokens the tokenizer should keep (based on frequency). The rest is ignored\n",
    "# MAX_LEN is the maximum length we set to all documents after being tokenized\n",
    "# is len(sequence) < MAX_LEN: keras tokenizer pads to the MAX_LEN with 0 values\n",
    "# is len(sequence) > MAX_LEN: keras tokenizer truncates to MAX_LEN\n",
    "\n",
    "NUM_WORDS = 100000\n",
    "MAX_LEN = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# initialize the tokenizer\n",
    "tokenizer = text.Tokenizer(num_words=NUM_WORDS)\n",
    "\n",
    "# fits it on train data\n",
    "tokenizer.fit_on_texts(tqdm_notebook(X_train['question_text'], leave=False))\n",
    "\n",
    "# use it to transform both train and test data\n",
    "train_sequences = tokenizer.texts_to_sequences(tqdm_notebook(X_train['question_text'], leave=False))\n",
    "test_sequences = tokenizer.texts_to_sequences(tqdm_notebook(X_test['question_text'], leave=False))\n",
    "\n",
    "# pad to MAX_LEN\n",
    "train_sequences_padded = sequence.pad_sequences(tqdm_notebook(train_sequences, leave=False), maxlen=MAX_LEN)\n",
    "test_sequences_padded = sequence.pad_sequences(tqdm_notebook(test_sequences, leave=False), maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the train output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     9,    48,  6683,  7219,   158,    55,\n",
       "         6107,    36,     4,  1206,     6,     1,  8333],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           11,    14,    24,    29,  3864,   498,     9,    35,    14,\n",
       "         3672,    37,     5,  3089,    10,    44,  1846],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,    16,    26,  2002,\n",
       "          374,    70,    26,  2002,   374,   451,  5546],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     9,    48,\n",
       "        13005,  8284, 52192,   119,     1, 39877, 28269],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,    15,     8,  1130, 42987, 99430,   911,     5,     4,\n",
       "         3133,  1533,    46,    96,  1465,     1,  9340]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_padded[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the corresponding shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with the test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375806, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the model architecture that will ingest this data.\n",
    "\n",
    "We'll keep it simple:\n",
    "\n",
    "- an embedding layer: basically a look-up table that converts each token in the dictionary to a vector with dense representation that will be learn and adjusted throughout training\n",
    "\n",
    "- two concatenated pooling layers with max and mean operations\n",
    "\n",
    "- a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we initialize the PyTorch model as a subclass of nn.Module\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # we define the embedding layer with a size equal to NUM_WORDS and an embedding dimension\n",
    "        # defined as a parameter in the constructor\n",
    "        self.embedding_layer = nn.Embedding(NUM_WORDS, embedding_dim)\n",
    "        self.embedding_layer.weight.requires_grad = True\n",
    "        \n",
    "        # we define a linear layer with an input size of MAX_LEN * 2 (because of the concatenation of two \n",
    "        # pooling operations)\n",
    "        self.fc1 = nn.Linear(MAX_LEN * 2, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # inputs shape : (batch_size, MAX_LEN)\n",
    "        \n",
    "        embedded_inputs = self.embedding_layer(inputs)\n",
    "        # embedded_inputs shape : (batch_size, MAX_LEN, embedding_dim)\n",
    "        \n",
    "        avg_pooled_inputs = torch.mean(embedded_inputs, -1)\n",
    "        # avg_pooled_inputs shape : (batch_size, MAX_LEN)\n",
    "        \n",
    "        max_pooled_inputs = torch.max(embedded_inputs, -1)[0]\n",
    "        # max_pooled_inputs shape : (batch_size, MAX_LEN)\n",
    "        \n",
    "        concat_pooled_layers = torch.cat([avg_pooled_inputs, max_pooled_inputs], -1)\n",
    "        # concat_pooled_layers shape : (batch_size, 2 * MAX_LEN)\n",
    "        \n",
    "        outputs = self.fc1(concat_pooled_layers)\n",
    "        # outputs shape : (batch_size, 1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a custom Dataset to load data very efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    # it takes two parameters in the constructor\n",
    "    # padded_sequencs: the sequences previously processed with padding\n",
    "    # labels: the corresponding targets\n",
    "    def __init__(self, padded_sequences, labels):\n",
    "        self.padded_sequences = padded_sequences\n",
    "        self.labels = labels\n",
    "    \n",
    "    \n",
    "    # special method to return the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.padded_sequences)\n",
    "    \n",
    "    # special method to get any given item at a given index while applying some preprocessings on it\n",
    "    def __getitem__(self, index):\n",
    "        # get a padded sequence\n",
    "        x = self.padded_sequences[index, :]\n",
    "        \n",
    "        # convert it to long tensor (because the values are actually indexes of mapping)\n",
    "        x = torch.LongTensor(x)  \n",
    "        \n",
    "        # convert the target to a float tensor\n",
    "        y = self.labels[index]\n",
    "        y = torch.Tensor([y])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define two functions I usually use in the main training loop:\n",
    "\n",
    "- compute_f1_score: takes a input y: the batch of labels, preds: the corresponding outputs of the models and computes the f1_score\n",
    "\n",
    "- print_metrics: prints at any given iteration, the current average loss and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score(y, preds, th=0.5):\n",
    "    y_preds_proba = torch.sigmoid(preds)\n",
    "    y_preds_proba = y_preds_proba.cpu().detach().numpy()\n",
    "    y_pred = (y_preds_proba > th).astype(int)\n",
    "    \n",
    "    y_true = y.detach().cpu().numpy()\n",
    "    f1 = f1_score(y_true=y_true, y_pred=y_pred)\n",
    "    return f1\n",
    "\n",
    "def print_metrics(iteration, total_iterations, epoch, total_epochs, loss_list, f1_list, print_every, train=True):\n",
    "    if train:\n",
    "        msg = f'Epoch: {epoch+1} / {total_epochs} |Iteration: {iteration} / {total_iterations} \\n'\n",
    "        msg += f'Average train loss: {np.mean(loss_list)} | Average train f1: {np.mean(f1_list)}'\n",
    "        \n",
    "    else:\n",
    "        msg = f'Epoch: {epoch+1} / {total_epochs} |Iteration: {iteration} / {total_iterations} \\n'\n",
    "        msg += f'Average val loss: {np.mean(loss_list)} | Average val f1: {np.mean(f1_list)}'\n",
    "        \n",
    "    if iteration % print_every == 0:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare a train and validation splits to train the model and consequently evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train_sequences_padded, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a train dataset and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(x_train, y_train)\n",
    "val_dataset = MyDataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two objects will allow us to create train and validation dataloader.\n",
    "\n",
    "Dataloaders are PyTorch objects that allow to load data efficiently. They handle batching, parallelizing over CPUs, and data augmentation among other things. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a batch size of 256 and initialize the train and val loaders over 5 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, num_workers=5, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, num_workers=5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the model and move it to the GPU for acceleration.\n",
    "\n",
    "We define the optimizer: Adam with learning rate : 0.003\n",
    "\n",
    "We define the loss: Binary Cross Entropy that i.e BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(300)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=0.003, params=model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the main training/evaluation process that loops over a given number of epochs.\n",
    "\n",
    "At each epoch, two loops:\n",
    "\n",
    "- a training loop over the train_loader: here the model is set to train mode. gradients are computed and weights are updated over each batch\n",
    "\n",
    "- a validation (evaluation) loop over the val_loader: here the model is set eval mode. we only compute predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db61e45e56a4dfc869049cd88a4e878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4082), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 5 |Iteration: 0 / 4082 \n",
      "Average train loss: 0.6260775327682495 | Average train f1: 0.19999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 5 |Iteration: 500 / 4082 \n",
      "Average train loss: 0.18710285529286086 | Average train f1: 0.11252626989612288\n",
      "Epoch: 1 / 5 |Iteration: 1000 / 4082 \n",
      "Average train loss: 0.16348664072173816 | Average train f1: 0.25080317049367945\n",
      "Epoch: 1 / 5 |Iteration: 1500 / 4082 \n",
      "Average train loss: 0.1533402460692407 | Average train f1: 0.31649104428495867\n",
      "Epoch: 1 / 5 |Iteration: 2000 / 4082 \n",
      "Average train loss: 0.14781327426865482 | Average train f1: 0.35293284083906173\n",
      "Epoch: 1 / 5 |Iteration: 2500 / 4082 \n",
      "Average train loss: 0.14394471271247303 | Average train f1: 0.38073687487435737\n",
      "Epoch: 1 / 5 |Iteration: 3000 / 4082 \n",
      "Average train loss: 0.1410980424652871 | Average train f1: 0.39870099247460805\n",
      "Epoch: 1 / 5 |Iteration: 3500 / 4082 \n",
      "Average train loss: 0.1390492692611041 | Average train f1: 0.41269331637219087\n",
      "Epoch: 1 / 5 |Iteration: 4000 / 4082 \n",
      "Average train loss: 0.13719365658446628 | Average train f1: 0.4246962444553369\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 5 |Iteration: 0 / 4082 \n",
      "Average val loss: 0.739369809627533 | Average val f1: 0.6250000000000001\n",
      "Epoch: 1 / 5 |Iteration: 150 / 4082 \n",
      "Average val loss: 0.7453723995890839 | Average val f1: 0.5147815091293765\n",
      "Epoch: 1 / 5 |Iteration: 300 / 4082 \n",
      "Average val loss: 0.7466469080345179 | Average val f1: 0.5173881524695083\n",
      "Epoch: 1 / 5 |Iteration: 450 / 4082 \n",
      "Average val loss: 0.7491616993944291 | Average val f1: 0.5149335667633373\n",
      "Epoch: 1 / 5 |Iteration: 600 / 4082 \n",
      "Average val loss: 0.7481068153547963 | Average val f1: 0.5139121578789464\n",
      "Epoch: 1 / 5 |Iteration: 750 / 4082 \n",
      "Average val loss: 0.7482267748341261 | Average val f1: 0.5134132743818568\n",
      "Epoch: 1 / 5 |Iteration: 900 / 4082 \n",
      "Average val loss: 0.7487260522641299 | Average val f1: 0.51291953515809\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4082), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 5 |Iteration: 0 / 4082 \n",
      "Average train loss: 0.1028328612446785 | Average train f1: 0.56\n",
      "Epoch: 2 / 5 |Iteration: 500 / 4082 \n",
      "Average train loss: 0.11273196277147282 | Average train f1: 0.5472655538915973\n",
      "Epoch: 2 / 5 |Iteration: 1000 / 4082 \n",
      "Average train loss: 0.11371267822893945 | Average train f1: 0.5515320923847151\n",
      "Epoch: 2 / 5 |Iteration: 1500 / 4082 \n",
      "Average train loss: 0.11365482674478532 | Average train f1: 0.5494643290394827\n",
      "Epoch: 2 / 5 |Iteration: 2000 / 4082 \n",
      "Average train loss: 0.11458761862542914 | Average train f1: 0.5459451937111124\n",
      "Epoch: 2 / 5 |Iteration: 2500 / 4082 \n",
      "Average train loss: 0.11500660484818305 | Average train f1: 0.5447619655614699\n",
      "Epoch: 2 / 5 |Iteration: 3000 / 4082 \n",
      "Average train loss: 0.11511111479551742 | Average train f1: 0.5460802078332058\n",
      "Epoch: 2 / 5 |Iteration: 3500 / 4082 \n",
      "Average train loss: 0.11545876390493554 | Average train f1: 0.5457131167295066\n",
      "Epoch: 2 / 5 |Iteration: 4000 / 4082 \n",
      "Average train loss: 0.11567545604352741 | Average train f1: 0.5462322606457682\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 5 |Iteration: 0 / 4082 \n",
      "Average val loss: 0.7291238903999329 | Average val f1: 0.6250000000000001\n",
      "Epoch: 2 / 5 |Iteration: 150 / 4082 \n",
      "Average val loss: 0.7428735668296056 | Average val f1: 0.5234909905283907\n",
      "Epoch: 2 / 5 |Iteration: 300 / 4082 \n",
      "Average val loss: 0.7441046293391738 | Average val f1: 0.5270866990663704\n",
      "Epoch: 2 / 5 |Iteration: 450 / 4082 \n",
      "Average val loss: 0.7467111035884088 | Average val f1: 0.5230776290282568\n",
      "Epoch: 2 / 5 |Iteration: 600 / 4082 \n",
      "Average val loss: 0.7455885829822394 | Average val f1: 0.5249078370463824\n",
      "Epoch: 2 / 5 |Iteration: 750 / 4082 \n",
      "Average val loss: 0.7457338054075381 | Average val f1: 0.5225577525221332\n",
      "Epoch: 2 / 5 |Iteration: 900 / 4082 \n",
      "Average val loss: 0.7459265944960379 | Average val f1: 0.5249203592896137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4082), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 5 |Iteration: 0 / 4082 \n",
      "Average train loss: 0.11115862429141998 | Average train f1: 0.5925925925925927\n",
      "Epoch: 3 / 5 |Iteration: 500 / 4082 \n",
      "Average train loss: 0.10916512768842027 | Average train f1: 0.5760886305732152\n",
      "Epoch: 3 / 5 |Iteration: 1000 / 4082 \n",
      "Average train loss: 0.10888447286886768 | Average train f1: 0.5819613688319033\n",
      "Epoch: 3 / 5 |Iteration: 1500 / 4082 \n",
      "Average train loss: 0.10890877820913748 | Average train f1: 0.5829059285371334\n",
      "Epoch: 3 / 5 |Iteration: 2000 / 4082 \n",
      "Average train loss: 0.10935459069829473 | Average train f1: 0.5813547658701198\n",
      "Epoch: 3 / 5 |Iteration: 2500 / 4082 \n",
      "Average train loss: 0.10945945630957488 | Average train f1: 0.5790436524633925\n",
      "Epoch: 3 / 5 |Iteration: 3000 / 4082 \n",
      "Average train loss: 0.10955759509404832 | Average train f1: 0.578526264393114\n",
      "Epoch: 3 / 5 |Iteration: 3500 / 4082 \n",
      "Average train loss: 0.1095404271999365 | Average train f1: 0.5779114034184927\n",
      "Epoch: 3 / 5 |Iteration: 4000 / 4082 \n",
      "Average train loss: 0.10972626338568785 | Average train f1: 0.5785920552145241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 5 |Iteration: 0 / 4082 \n",
      "Average val loss: 0.7061707377433777 | Average val f1: 0.7058823529411765\n",
      "Epoch: 3 / 5 |Iteration: 150 / 4082 \n",
      "Average val loss: 0.7251459896959216 | Average val f1: 0.5457804876915987\n",
      "Epoch: 3 / 5 |Iteration: 300 / 4082 \n",
      "Average val loss: 0.726689200068629 | Average val f1: 0.5505327782095749\n",
      "Epoch: 3 / 5 |Iteration: 450 / 4082 \n",
      "Average val loss: 0.7294037320925761 | Average val f1: 0.548843354054185\n",
      "Epoch: 3 / 5 |Iteration: 600 / 4082 \n",
      "Average val loss: 0.7285346065503785 | Average val f1: 0.5509294184803266\n",
      "Epoch: 3 / 5 |Iteration: 750 / 4082 \n",
      "Average val loss: 0.7283126215007747 | Average val f1: 0.550755198665633\n",
      "Epoch: 3 / 5 |Iteration: 900 / 4082 \n",
      "Average val loss: 0.7284937068968846 | Average val f1: 0.5526674498587693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4082), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / 5 |Iteration: 0 / 4082 \n",
      "Average train loss: 0.1076628789305687 | Average train f1: 0.4166666666666667\n",
      "Epoch: 4 / 5 |Iteration: 500 / 4082 \n",
      "Average train loss: 0.1029508417684161 | Average train f1: 0.6052959085948069\n",
      "Epoch: 4 / 5 |Iteration: 1000 / 4082 \n",
      "Average train loss: 0.10444203830444133 | Average train f1: 0.6075418267922074\n",
      "Epoch: 4 / 5 |Iteration: 1500 / 4082 \n",
      "Average train loss: 0.10423376523876571 | Average train f1: 0.605609909622825\n",
      "Epoch: 4 / 5 |Iteration: 2000 / 4082 \n",
      "Average train loss: 0.10425597729570028 | Average train f1: 0.604470553690709\n",
      "Epoch: 4 / 5 |Iteration: 2500 / 4082 \n",
      "Average train loss: 0.10442806529503067 | Average train f1: 0.602266636477872\n",
      "Epoch: 4 / 5 |Iteration: 3000 / 4082 \n",
      "Average train loss: 0.10489600399798928 | Average train f1: 0.600860300538997\n",
      "Epoch: 4 / 5 |Iteration: 3500 / 4082 \n",
      "Average train loss: 0.10551977866259822 | Average train f1: 0.5996134449719115\n",
      "Epoch: 4 / 5 |Iteration: 4000 / 4082 \n",
      "Average train loss: 0.10584830109219019 | Average train f1: 0.5989684732295464\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / 5 |Iteration: 0 / 4082 \n",
      "Average val loss: 0.7209623456001282 | Average val f1: 0.6\n",
      "Epoch: 4 / 5 |Iteration: 150 / 4082 \n",
      "Average val loss: 0.7380385651493704 | Average val f1: 0.5229428677971403\n",
      "Epoch: 4 / 5 |Iteration: 300 / 4082 \n",
      "Average val loss: 0.7392194912679172 | Average val f1: 0.5320281943140253\n",
      "Epoch: 4 / 5 |Iteration: 450 / 4082 \n",
      "Average val loss: 0.7423648987535363 | Average val f1: 0.5272940449358879\n",
      "Epoch: 4 / 5 |Iteration: 600 / 4082 \n",
      "Average val loss: 0.7413579248350591 | Average val f1: 0.5310152188627079\n",
      "Epoch: 4 / 5 |Iteration: 750 / 4082 \n",
      "Average val loss: 0.7413006431253233 | Average val f1: 0.5302632941617091\n",
      "Epoch: 4 / 5 |Iteration: 900 / 4082 \n",
      "Average val loss: 0.7414083823512053 | Average val f1: 0.5322610179114294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4082), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / 5 |Iteration: 0 / 4082 \n",
      "Average train loss: 0.10147333890199661 | Average train f1: 0.5925925925925927\n",
      "Epoch: 5 / 5 |Iteration: 500 / 4082 \n",
      "Average train loss: 0.09903993588424252 | Average train f1: 0.6277760015321595\n",
      "Epoch: 5 / 5 |Iteration: 1000 / 4082 \n",
      "Average train loss: 0.09934390951822569 | Average train f1: 0.6221800394442988\n",
      "Epoch: 5 / 5 |Iteration: 1500 / 4082 \n",
      "Average train loss: 0.10024081324435011 | Average train f1: 0.6194852238432089\n",
      "Epoch: 5 / 5 |Iteration: 2000 / 4082 \n",
      "Average train loss: 0.10065948530689053 | Average train f1: 0.6205277291056779\n",
      "Epoch: 5 / 5 |Iteration: 2500 / 4082 \n",
      "Average train loss: 0.10144812276498263 | Average train f1: 0.6173487911205533\n",
      "Epoch: 5 / 5 |Iteration: 3000 / 4082 \n",
      "Average train loss: 0.10207413128145493 | Average train f1: 0.615753287589061\n",
      "Epoch: 5 / 5 |Iteration: 3500 / 4082 \n",
      "Average train loss: 0.10238519173474081 | Average train f1: 0.6142481513191413\n",
      "Epoch: 5 / 5 |Iteration: 4000 / 4082 \n",
      "Average train loss: 0.10275685689902044 | Average train f1: 0.6138847225832684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / 5 |Iteration: 0 / 4082 \n",
      "Average val loss: 0.7062171697616577 | Average val f1: 0.7222222222222222\n",
      "Epoch: 5 / 5 |Iteration: 150 / 4082 \n",
      "Average val loss: 0.7288045555550531 | Average val f1: 0.5444146144199118\n",
      "Epoch: 5 / 5 |Iteration: 300 / 4082 \n",
      "Average val loss: 0.7302469365620534 | Average val f1: 0.5494088447691461\n",
      "Epoch: 5 / 5 |Iteration: 450 / 4082 \n",
      "Average val loss: 0.7332742641083153 | Average val f1: 0.5436537338174602\n",
      "Epoch: 5 / 5 |Iteration: 600 / 4082 \n",
      "Average val loss: 0.7321674872357119 | Average val f1: 0.5461457383544558\n",
      "Epoch: 5 / 5 |Iteration: 750 / 4082 \n",
      "Average val loss: 0.7319254773593298 | Average val f1: 0.5448036607959894\n",
      "Epoch: 5 / 5 |Iteration: 900 / 4082 \n",
      "Average val loss: 0.7319583415191261 | Average val f1: 0.5467584581568314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "print_every_train = 500\n",
    "print_every_val = 150\n",
    "\n",
    "\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    \n",
    "    # train model\n",
    "    \n",
    "    f1_scores_train = []\n",
    "    losses_train = []\n",
    "\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(tqdm_notebook(train_loader, leave=False, total=len(train_loader))):\n",
    "        \n",
    "        # pass batches to GPU\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute predictions: forward pass on the batch\n",
    "        preds = model.forward(x)\n",
    "        \n",
    "        # compute the loss on the batch\n",
    "        loss = criterion(preds, y)\n",
    "        \n",
    "        # compute the gardients by derivating the loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of losses and f1 scores for each epoch\n",
    "        losses_train.append(loss.item())\n",
    "        \n",
    "        f1_score_train = compute_f1_score(y, preds)\n",
    "        f1_scores_train.append(f1_score_train)\n",
    "        \n",
    "        # print metrics\n",
    "        print_metrics(i, len(train_loader), epoch, num_epochs, losses_train, f1_scores_train, print_every_train)\n",
    "        \n",
    "    # evaluation mode\n",
    "        \n",
    "    f1_scores_val = []\n",
    "    losses_val = []\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (x, y) in enumerate(tqdm_notebook(val_loader, leave=False, total=len(val_loader))):\n",
    "        \n",
    "        # pass batches to GPU\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        # make predictions\n",
    "        preds = model.forward(x)\n",
    "        \n",
    "        # computes the losses and f1 scores\n",
    "        loss = criterion(y, preds)\n",
    "        losses_val.append(loss.item())\n",
    "        \n",
    "        f1_score_val = compute_f1_score(y, preds)\n",
    "        f1_scores_val.append(f1_score_val)\n",
    "        \n",
    "        # print metrics\n",
    "        print_metrics(i, len(train_loader), epoch, num_epochs, losses_val, f1_scores_val, print_every_val, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_sequences_padded[:1]\n",
    "inputs = torch.LongTensor(inputs).cuda()\n",
    "\n",
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = make_dot(outputs, params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"386pt\" height=\"283pt\"\n",
       " viewBox=\"0.00 0.00 385.50 283.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 279)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-279 381.5,-279 381.5,4 -4,4\"/>\n",
       "<!-- 140563763029216 -->\n",
       "<g id=\"node1\" class=\"node\"><title>140563763029216</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"245,-21 127,-21 127,-0 245,-0 245,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">ThAddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140563688088688 -->\n",
       "<g id=\"node2\" class=\"node\"><title>140563688088688</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"102,-78 7.10543e-15,-78 7.10543e-15,-57 102,-57 102,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"51\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140563688088688&#45;&gt;140563763029216 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>140563688088688&#45;&gt;140563763029216</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.5152,-56.9197C96.1603,-48.1014 128.493,-34.9287 152.773,-25.0369\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.361,-28.1694 162.301,-21.155 151.72,-21.6867 154.361,-28.1694\"/>\n",
       "</g>\n",
       "<!-- 140563688088856 -->\n",
       "<g id=\"node3\" class=\"node\"><title>140563688088856</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"66,-148 12,-148 12,-114 66,-114 66,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"39\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\">fc1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"39\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140563688088856&#45;&gt;140563688088688 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>140563688088856&#45;&gt;140563688088688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.1529,-113.842C43.6979,-105.923 45.5709,-96.3241 47.195,-88.0006\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"50.6582,-88.5271 49.1382,-78.0419 43.7878,-87.1865 50.6582,-88.5271\"/>\n",
       "</g>\n",
       "<!-- 140563688089248 -->\n",
       "<g id=\"node4\" class=\"node\"><title>140563688089248</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"227,-78 145,-78 145,-57 227,-57 227,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">CatBackward</text>\n",
       "</g>\n",
       "<!-- 140563688089248&#45;&gt;140563763029216 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>140563688089248&#45;&gt;140563763029216</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M186,-56.9197C186,-49.9083 186,-40.1442 186,-31.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"189.5,-31.3408 186,-21.3408 182.5,-31.3409 189.5,-31.3408\"/>\n",
       "</g>\n",
       "<!-- 140563688089024 -->\n",
       "<g id=\"node5\" class=\"node\"><title>140563688089024</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"182,-141.5 84,-141.5 84,-120.5 182,-120.5 182,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 140563688089024&#45;&gt;140563688089248 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>140563688089024&#45;&gt;140563688089248</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.281,-120.391C149.169,-111.238 161.231,-97.2409 170.841,-86.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.725,-88.1049 177.602,-78.2449 168.422,-83.5352 173.725,-88.1049\"/>\n",
       "</g>\n",
       "<!-- 140563688089192 -->\n",
       "<g id=\"node6\" class=\"node\"><title>140563688089192</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"249,-205 129,-205 129,-184 249,-184 249,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">EmbeddingBackward</text>\n",
       "</g>\n",
       "<!-- 140563688089192&#45;&gt;140563688089024 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>140563688089192&#45;&gt;140563688089024</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M180.25,-183.891C171.834,-174.648 158.92,-160.466 148.719,-149.263\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"151.194,-146.782 141.873,-141.745 146.018,-151.495 151.194,-146.782\"/>\n",
       "</g>\n",
       "<!-- 140563688088912 -->\n",
       "<g id=\"node8\" class=\"node\"><title>140563688088912</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"292.5,-141.5 199.5,-141.5 199.5,-120.5 292.5,-120.5 292.5,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"246\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\">MaxBackward0</text>\n",
       "</g>\n",
       "<!-- 140563688089192&#45;&gt;140563688088912 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>140563688089192&#45;&gt;140563688088912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197.906,-183.891C206.473,-174.648 219.617,-160.466 230,-149.263\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"232.738,-151.458 236.968,-141.745 227.603,-146.7 232.738,-151.458\"/>\n",
       "</g>\n",
       "<!-- 140563688089304 -->\n",
       "<g id=\"node7\" class=\"node\"><title>140563688089304</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"256,-275 122,-275 122,-241 256,-241 256,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\">embedding_layer.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (100000, 300)</text>\n",
       "</g>\n",
       "<!-- 140563688089304&#45;&gt;140563688089192 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>140563688089304&#45;&gt;140563688089192</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M189,-240.842C189,-233.012 189,-223.54 189,-215.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"192.5,-215.042 189,-205.042 185.5,-215.042 192.5,-215.042\"/>\n",
       "</g>\n",
       "<!-- 140563688088912&#45;&gt;140563688089248 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>140563688088912&#45;&gt;140563688089248</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M236.625,-120.391C227.52,-111.058 213.503,-96.6902 202.524,-85.4374\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.996,-82.9586 195.507,-78.2449 199.985,-87.8468 204.996,-82.9586\"/>\n",
       "</g>\n",
       "<!-- 140563688088800 -->\n",
       "<g id=\"node9\" class=\"node\"><title>140563688088800</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"367.5,-78 294.5,-78 294.5,-57 367.5,-57 367.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"331\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140563688088800&#45;&gt;140563763029216 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>140563688088800&#45;&gt;140563763029216</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M305.743,-56.9197C282.288,-48.023 247.148,-34.6942 220.995,-24.7739\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.045,-21.4291 211.454,-21.155 219.563,-27.9741 222.045,-21.4291\"/>\n",
       "</g>\n",
       "<!-- 140563688089136 -->\n",
       "<g id=\"node10\" class=\"node\"><title>140563688089136</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"377.5,-148 310.5,-148 310.5,-114 377.5,-114 377.5,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"344\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\">fc1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"344\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1, 50)</text>\n",
       "</g>\n",
       "<!-- 140563688089136&#45;&gt;140563688088800 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>140563688089136&#45;&gt;140563688088800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M340.584,-113.842C338.911,-105.923 336.882,-96.3241 335.122,-88.0006\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"338.51,-87.1018 333.017,-78.0419 331.661,-88.5496 338.51,-87.1018\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fd78d29ebe0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
