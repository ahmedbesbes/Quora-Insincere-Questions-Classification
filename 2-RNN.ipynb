{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I propose a more sophisticated model that achieves better validation F1 score (see end of the notebook)\n",
    "\n",
    "Improvements include:\n",
    "\n",
    "- advanced text processing and cleaning\n",
    "- a custom tokenizer based on Spacy and its english language model\n",
    "- a FastText binary model to initialize an embedding matrix from character-ngrams (i.e. no out-of-vocabulary words)\n",
    "- use of a stacked bi-LSTM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d6f22f710d4549acc353cf9d9857f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# pandas and numpy for dataframes and array manipulations\n",
    "# tqdm as a progress\n",
    "# matplotlib for plotting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# usual PyTorch imports for tensor manipulations, neural networks and data processings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import some sklearn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# import keras tokenizing utilities \n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "# import tensorboardX in case we want to log metrics to tensorboard (requires tensorflow installed - optional)\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from graphviz import Digraph\n",
    "from torchviz import make_dot\n",
    "\n",
    "\n",
    "# import spacy for tokenization\n",
    "import spacy\n",
    "\n",
    "# fastText is a library for efficient learning of word representations and sentence classification\n",
    "# https://github.com/facebookresearch/fastText/tree/master/python\n",
    "# I use it with a pre-trained english embedding that you can fetch from the official website\n",
    "import fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load english spacy model and disable ner, parser, tagger to make it faster\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load train and test data and separate the target in another variable\n",
    "\n",
    "X_train = pd.read_csv('./data/train.csv')\n",
    "X_test = pd.read_csv('./data/test.csv')\n",
    "Y = X_train['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we start by preprocessing the text: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457e686d145449dc83193b4f3a56a8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7958ff51e150405fba500087b7d5a763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decontract\n",
    "\n",
    "def decontract(text):\n",
    "    text = re.sub(r\"(W|w)on(\\'|\\’)t \", \"will not \", text)\n",
    "    text = re.sub(r\"(C|c)an(\\'|\\’)t \", \"can not \", text)\n",
    "    text = re.sub(r\"(Y|y)(\\'|\\’)all \", \"you all \", text)\n",
    "    text = re.sub(r\"(Y|y)a(\\'|\\’)ll \", \"you all \", text)\n",
    "    text = re.sub(r\"(I|i)(\\'|\\’)m \", \"i am \", text)\n",
    "    text = re.sub(r\"(A|a)isn(\\'|\\’)t \", \"is not \", text)\n",
    "    text = re.sub(r\"n(\\'|\\’)t \", \" not \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)re \", \" are \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)d \", \" would \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)ll \", \" will \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)t \", \" not \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)ve \", \" have \", text)\n",
    "    return text\n",
    "\n",
    "X_train['question_text'] = X_train['question_text'].progress_map(lambda q: decontract(q))\n",
    "X_test['question_text'] = X_test['question_text'].progress_map(lambda q: decontract(q)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002829fcff1d450db2c31b03a10bcd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2597a6c5ae74ec4a6cd605f12d89eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clean apostrophes\n",
    "\n",
    "def clean_apostrophes(x):\n",
    "    apostrophes = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in apostrophes:\n",
    "        x = re.sub(s, \"'\", x)\n",
    "    return x\n",
    "\n",
    "\n",
    "X_train['question_text'] = X_train['question_text'].progress_map(lambda q: clean_apostrophes(q))\n",
    "X_test['question_text'] = X_test['question_text'].progress_map(lambda q: clean_apostrophes(q)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ae682cd3874b5a969e89357329fde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2269fbb4a92e4ab183e16fa598ee4b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clean weird / special characters\n",
    "\n",
    "letter_mapping = {'\\u200b':' ', 'ũ': \"u\", 'ẽ': 'e', 'é': \"e\", 'á': \"a\", 'ķ': 'k', 'ï': 'i', 'Ź': 'Z', 'Ż': 'Z', 'Š': 'S', 'Π': ' pi ', 'Ö': 'O', 'É': 'E', 'Ñ': 'N', 'Ž': 'Z', 'ệ': 'e', '²': '2', 'Å': 'A', 'Ā': 'A', 'ế': 'e', 'ễ': 'e', 'ộ': 'o', '⧼': '<', '⧽': '>', 'Ü': 'U', 'Δ': 'delta', 'ợ': 'o', 'İ': 'I', 'Я': 'R', 'О': 'O', 'Č': 'C', 'П': 'pi', 'В': 'B', 'Φ': 'phi', 'ỵ': 'y', 'օ': 'o', 'Ľ': 'L', 'ả': 'a', 'Γ': 'theta', 'Ó': 'O', 'Í': 'I', 'ấ': 'a', 'ụ': 'u', 'Ō': 'O', 'Ο': 'O', 'Σ': 'sigma', 'Â': 'A', 'Ã': 'A', 'ᗯ': 'w', 'ᕼ': \"h\", \"ᗩ\": \"a\", \"ᖇ\": \"r\", \"ᗯ\": \"w\", \"O\": \"o\", \"ᗰ\": \"m\", \"ᑎ\": \"n\", \"ᐯ\": \"v\", \"н\": \"h\", \"м\": \"m\", \"o\": \"o\", \"т\": \"t\", \"в\": \"b\", \"υ\": \"u\",  \"ι\": \"i\",\"н\": \"h\", \"č\": \"c\", \"š\": \"s\", \"ḥ\": \"h\", \"ā\": \"a\", \"ī\": \"i\", \"à\": \"a\", \"ý\": \"y\", \"ò\": \"o\", \"è\": \"e\", \"ù\": \"u\", \"â\": \"a\", \"ğ\": \"g\", \"ó\": \"o\", \"ê\": \"e\", \"ạ\": \"a\", \"ü\": \"u\", \"ä\": \"a\", \"í\": \"i\", \"ō\": \"o\", \"ñ\": \"n\", \"ç\": \"c\", \"ã\": \"a\", \"ć\": \"c\", \"ô\": \"o\", \"с\": \"c\", \"ě\": \"e\", \"æ\": \"ae\", \"î\": \"i\", \"ő\": \"o\", \"å\": \"a\", \"Ä\": \"A\", } \n",
    "\n",
    "def clean_special_chars(text):\n",
    "    new_text = ''\n",
    "    for i in range(len(text)):\n",
    "        if i in letter_mapping:\n",
    "            c = letter_mapping[i]\n",
    "        else:\n",
    "            c = text[i]\n",
    "        new_text += c\n",
    "    return new_text\n",
    "\n",
    "\n",
    "X_train['question_text'] = X_train['question_text'].progress_map(lambda q: clean_special_chars(q))\n",
    "X_test['question_text'] = X_test['question_text'].progress_map(lambda q: clean_special_chars(q)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b386de109151442993dfa2cedef19b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01eef7e86654488931d5869aa63affb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove useless punctuations\n",
    "\n",
    "useless_punct = ['च', '不', 'ঢ়', '平', 'ᠠ', '錯', '判', '∙', '言', 'ς', 'ل', '្', 'ジ', 'あ', '得', '水', 'ь', '◦', '创', '康', '華', 'ḵ', '☺', '支', '就', '„', '」', '어', '谈', '陈', '团', '腻', '权', '年', '业', 'マ', 'य', 'ا', '売', '甲', '拼', '˂', 'ὤ', '贯', '亚', 'ि', '放', 'ʻ', 'ទ', 'ʖ', '點', '્', '発', '青', '能', '木', 'д', '微', '藤', '̃', '僕', '妒', '͜', 'ន', 'ध', '이', '希', '特', 'ड', '¢', '滢', 'ส', '나', '女', 'క', '没', '什', 'з', '天', '南', 'ʿ', 'ค', 'も', '凰', '步', '籍', '西', 'ำ', '−', 'л', 'ڤ', 'ៃ', '號', 'ص', 'स', '®', 'ʋ', '批', 'រ', '치', '谢', '生', '道', '═', '下', '俄', 'ɖ', '觀', 'வ', '—', 'ی', '您', '♥', '一', 'や', '⊆', 'ʌ', '語', 'ี', '兴', '惶', '瀛', '狐', '⁴', 'प', '臣', 'ద', '―', 'ì', 'ऌ', 'ీ', '自', '信', '健', '受', 'ɨ', '시', 'י', 'ছ', '嬛', '湾', '吃', 'ち', 'ड़', '反', '红', '有', '配', 'ে', 'ឯ', '宮', 'つ', 'μ', '記', '口', '℅ι', 'ो', '狸', '奇', 'о', 'ट', '聖', '蘭', '読', 'ū', '標', '要', 'ត', '识', 'で', '汤', 'ま', 'ʀ', '局', 'リ', '्', 'ไ', '呢', '工', 'ल', '沒', 'τ', 'ិ', 'ö', 'せ', '你', 'ん', 'ュ', '枚', '部', '大', '罗', 'হ', 'て', '表', '报', '攻', 'ĺ', 'ฉ', '∩', '宝', '对', '字', '文', '这', '∑', '髪', 'り', '่', '능', '罢', '내', '阻', '为', '菲', 'ي', 'न', 'ί', 'ɦ', '開', '†', '茹', '做', '東', 'ত', 'に', 'ت', '晓', '키', '悲', 'સ', '好', '›', '上', '存', '없', '하', '知', 'ធ', '斯', ' ', '授', 'ł', '傳', '兰', '封', 'ோ', 'و', 'х', 'だ', '人', '太', '品', '毒', 'ᡳ', '血', '席', '剔', 'п', '蛋', '王', '那', '梦', 'ី', '彩', '甄', 'и', '柏', 'ਨ', '和', '坊', '⌚', '广', '依', '∫', 'į', '故', 'ś', 'ऊ', '几', '日', 'ک', '音', '×', '”', '▾', 'ʊ', 'ज', 'ด', 'ठ', 'उ', 'る', '清', 'ग', 'ط', 'δ', 'ʏ', '官', '∛', '়', '้', '男', '骂', '复', '∂', 'ー', '过', 'য', '以', '短', '翻', 'র', '教', '儀', 'ɛ', '‹', 'へ', '¾', '合', '学', 'ٌ', '학', '挑', 'ष', '比', '体', 'م', 'س', 'អ', 'ת', '訓', '∀', '迎', 'វ', 'ɔ', '٨', '▒', '化', 'చ', '‛', 'প', 'º', 'น', '업', '说', 'ご', '¸', '₹', '儿', '︠', '게', '骨', 'ท', 'ऋ', 'ホ', '茶', '는', 'જ', 'ุ', '羡', '節', 'ਮ', 'উ', '番', 'ড়', '讲', 'ㅜ', '등', '伟', 'จ', '我', 'ล', 'す', 'い', 'ញ', '看', 'ċ', '∧', 'भ', 'ઘ', 'ั', 'ម', '街', 'ય', '还', '鰹', 'ខ', 'ు', '訊', 'म', 'ю', '復', '杨', 'ق', 'त', '金', '味', 'ব', '风', '意', '몇', '佬', '爾', '精', '¶', 'ం', '乱', 'χ', '교', 'ה', '始', 'ᠰ', '了', '个', '克', '্', 'ห', '已', 'ʃ', 'わ', '新', '译', '︡', '本', 'ง', 'б', 'け', 'ి', '明', '¯', '過', 'ك', 'ῥ', 'ف', 'ß', '서', '进', 'ដ', '样', '乐', '寧', '€', 'ณ', 'ル', '乡', '子', 'ﬁ', 'ج', '慕', '–', 'ᡵ', 'Ø', '͡', '제', 'Ω', 'ប', '絕', '눈', 'फ', 'ম', 'గ', '他', 'α', 'ξ', '§', 'ஜ', '黎', 'ね', '복', 'π', 'ú', '鸡', '话', '会', 'ক', '八', '之', '북', 'ن', '¦', '가', 'ו', '恋', '地', 'ῆ', '許', '产', 'ॡ', 'ش', '़', '野', 'ή', 'ɒ', '啧', 'យ', '᠌', 'ᠨ', 'ب', '皎', '老', '公', '☆', 'व', 'ি', 'ល', 'ر', 'គ', '행', 'ង', 'ο', '让', 'ំ', 'λ', 'خ', 'ἰ', '家', 'ট', 'ब', '理', '是', 'め', 'र', '√', '기', 'ν', '玉', '한', '入', 'ד', '别', 'د', 'ะ', '电', 'ા', '♫', 'ع', 'ં', '堵', '嫉', '伊', 'う', '千', '관', '篇', 'क', '非', '荣', '粵', '瑜', '英', '를', '美', '条', '`', '宋', '←', '수', '後', '•', '³', 'ी', '고', '肉', '℃', 'し', '漢', '싱', 'ϵ', '送', 'ه', '落', 'న', 'ក', 'க', 'ℇ', 'た', 'ះ', '中', '射', '♪', '符', 'ឃ', '谷', '分', '酱', 'び', 'থ', 'ة', 'г', 'σ', 'と', '楚', '胡', '饭', 'み', '禮', '主', '直', '÷', '夢', 'ɾ', 'চ', '⃗', '統', '高', '顺', '据', 'ら', '頭', 'よ', '最', 'ా', 'ੁ', '亲', 'ស', '花', '≡', '眼', '病', '…', 'の', '發', 'ா', '汝', '★', '氏', 'ร', '景', 'ᡠ', '读', '件', '仲', 'শ', 'お', 'っ', 'پ', 'ᡤ', 'ч', '♭', '悠', 'ं', '六', '也', 'ռ', 'য়', '恐', 'ह', '可', '啊', '莫', '书', '总', 'ষ', 'ք', '̂', '간', 'な', '此', '愛', 'ర', 'ใ', '陳', 'Ἀ', 'ण', '望', 'द', '请', '油', '露', '니', 'ş', '宗', 'ʍ', '鳳', 'अ', '邋', '的', 'ព', '火', 'ा', 'ก', '約', 'ட', '章', '長', '商', '台', '勢', 'さ', '국', 'Î', '簡', 'ई', '∈', 'ṭ', '經', '族', 'ु', '孫', '身', '坑', 'স', '么', 'ε', '失', '殺', 'ž', 'ર', 'が', '手', 'ា', '心', 'ਾ', '로', '朝', '们', '黒', '欢', '早', '️', 'া', 'आ', 'ɸ', '常', '快', '民', 'ﷺ', 'ូ', '遢', 'η', '国', '无', '江', 'ॠ', '「', 'ন', '™', 'ើ', 'ζ', '紫', 'ె', 'я', '“', '♨', '國', 'े', 'อ', '∞']\n",
    "useless_punct.remove(' ')\n",
    "\n",
    "def remove_useless_punct(text):\n",
    "    return re.sub(f'{\"|\".join(useless_punct)}', '', text)\n",
    "\n",
    "\n",
    "X_train['question_text'] = X_train['question_text'].progress_map(lambda q: remove_useless_punct(q))\n",
    "X_test['question_text'] = X_test['question_text'].progress_map(lambda q: remove_useless_punct(q)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tokenization parameters \n",
    "\n",
    "MAX_WORDS = 100000\n",
    "MAX_LEN = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize train and test sequences and build word index\n",
    "\n",
    "all_questions = X_train['question_text'].tolist() + X_test['question_text'].tolist()\n",
    "\n",
    "word_index = {}\n",
    "x_train = []\n",
    "x_test = []\n",
    "\n",
    "c = 0\n",
    "for doc in tqdm_notebook(nlp.pipe(all_questions, n_threads=10), total=len(all_questions)):\n",
    "    \n",
    "    tokens = [token.text.lower() for token in doc]\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in word_index:\n",
    "            word_index[token] = 1\n",
    "        else:\n",
    "            word_index[token] += 1\n",
    "\n",
    "    if c < X_train.shape[0]:\n",
    "        x_train.append(tokens)\n",
    "    else:\n",
    "        x_test.append(tokens)\n",
    "        \n",
    "    c += 1\n",
    "\n",
    "word_index = dict(sorted(zip(word_index.keys(), word_index.values()), key=lambda c: c[1], reverse=True))\n",
    "for i, word in enumerate(word_index):\n",
    "    word_index[word] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert train and test word sequences to sequences of indexes while ignoring unfrequent words\n",
    "\n",
    "def convert_to_indexes(sequence, word_index, max_words=MAX_WORDS):\n",
    "    output = []\n",
    "    for token in sequence:\n",
    "        if (token in word_index) and (word_index[token] < max_words): \n",
    "            output.append(word_index[token])\n",
    "    return output\n",
    "\n",
    "\n",
    "x_train_idx = [convert_to_indexes(seq, word_index) for seq in tqdm_notebook(x_train, leave=False)]\n",
    "x_test_idx = [convert_to_indexes(seq, word_index) for seq in tqdm_notebook(x_test, leave=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pad train and test sequences\n",
    "\n",
    "x_train_padded = sequence.pad_sequences(tqdm_notebook(x_train_idx, leave=False), maxlen=MAX_LEN)\n",
    "x_test_padded = sequence.pad_sequences(tqdm_notebook(x_test_idx, leave=False), maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_type = 'fasttext'\n",
    "\n",
    "if embedding_type == 'glove':\n",
    "\n",
    "    def load_embedding(path):\n",
    "        embedding = {}\n",
    "        with open(path, 'r') as f:\n",
    "            for line in tqdm_notebook(f.readlines()):\n",
    "                k = line.split(' ')[0]\n",
    "                v = line.split(' ')[1:]\n",
    "                embedding[k] = np.array(v, dtype=float)\n",
    "        return embedding\n",
    "\n",
    "    glove = load_embedding('./embeddings/glove.840B.300d/glove.840B.300d.txt')\n",
    "\n",
    "    mean_emb = -0.005838493338505765\n",
    "    std_emb = 0.48782081729236354\n",
    "    \n",
    "else:\n",
    "    fasttext_model = fastText.load_model('/data_science/nlp/embeddings/fasttext/wiki.en.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_matrix_glove(word_index, embedding, embed_size=300):\n",
    "    matrix = np.zeros((min(MAX_WORDS, len(word_index) + 1), embed_size))\n",
    "    oov = []\n",
    "    for word, i in tqdm_notebook(word_index.items(), leave=False):\n",
    "        if word in embedding:\n",
    "            try:\n",
    "                matrix[i, :] = embedding[word]\n",
    "            except IndexError as e:\n",
    "                break\n",
    "        else:\n",
    "            try:\n",
    "                matrix[i, :] = np.random.normal(mean_emb, std_emb, (embed_size))\n",
    "            except IndexError as e:\n",
    "                break\n",
    "            oov.append(word)\n",
    "    return matrix, oov\n",
    "\n",
    "def build_embedding_matrix_with_fasttext(word_index, model, embed_size=300):\n",
    "    matrix = np.zeros((min(MAX_WORDS, len(word_index) + 1), embed_size))\n",
    "    for word, i in tqdm_notebook(word_index.items(), leave=False):\n",
    "        try:\n",
    "            matrix[i, :] = fasttext_model.get_word_vector(word)\n",
    "        except IndexError as e:\n",
    "            break\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f128a529c2614b5b8b4ca977bdc2722f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=250842), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if embedding_type == 'glove':\n",
    "    embedding_matrix, oov = build_embedding_matrix_glove(word_index, glove)\n",
    "    \n",
    "elif embedding_type == 'fasttext':\n",
    "    embedding_matrix = build_embedding_matrix_with_fasttext(word_index, fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build our Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_matrix):\n",
    "        super(Model, self).__init__()\n",
    "        vocab_size = embedding_matrix.shape[0]\n",
    "        embedding_dim = embedding_matrix.shape[1]\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_layer.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding_layer.weight.requires_grad = True\n",
    "        \n",
    "        self.hidden_units = 64\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embedding_dim, self.hidden_units, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(self.hidden_units * 2, self.hidden_units, bidirectional=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.hidden_units * 2 * 2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "    \n",
    "        # global average pooling\n",
    "        h_avg = torch.mean(x, 1)\n",
    "        \n",
    "        # global max pooling\n",
    "        h_max = torch.max(x, 1)[0]\n",
    "        \n",
    "        # concat the two pooling results\n",
    "        h_concat = torch.cat((h_avg, h_max), 1)\n",
    "        \n",
    "        # pass to a fully conncected layer\n",
    "        output = self.fc1(h_concat)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    # it takes two parameters in the constructor\n",
    "    # padded_sequencs: the sequences previously processed with padding\n",
    "    # labels: the corresponding targets\n",
    "    def __init__(self, padded_sequences, labels):\n",
    "        self.padded_sequences = padded_sequences\n",
    "        self.labels = labels\n",
    "    \n",
    "    \n",
    "    # special method to return the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.padded_sequences)\n",
    "    \n",
    "    # special method to get any given item at a given index while applying some preprocessings on it\n",
    "    def __getitem__(self, index):\n",
    "        # get a padded sequence\n",
    "        x = self.padded_sequences[index, :]\n",
    "        \n",
    "        # convert it to long tensor (because the values are actually indexes of mapping)\n",
    "        x = torch.LongTensor(x)  \n",
    "        \n",
    "        # convert the target to a float tensor\n",
    "        y = self.labels[index]\n",
    "        y = torch.Tensor([y])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define two functions I usually use in the main training loop:\n",
    "\n",
    "- compute_f1_score: takes a input y: the batch of labels, preds: the corresponding outputs of the models and computes the f1_score\n",
    "\n",
    "- print_metrics: prints at any given iteration, the current average loss and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score(y, preds, th=0.5):\n",
    "    y_preds_proba = torch.sigmoid(preds)\n",
    "    y_preds_proba = y_preds_proba.cpu().detach().numpy()\n",
    "    y_pred = (y_preds_proba > th).astype(int)\n",
    "    \n",
    "    y_true = y.detach().cpu().numpy()\n",
    "    f1 = f1_score(y_true=y_true, y_pred=y_pred)\n",
    "    return f1\n",
    "\n",
    "def print_metrics(iteration, total_iterations, epoch, total_epochs, loss_list, f1_list, print_every, train=True):\n",
    "    if train:\n",
    "        msg = f'Epoch: {epoch+1} / {total_epochs} |Iteration: {iteration} / {total_iterations} \\n'\n",
    "        msg += f'Average train loss: {np.mean(loss_list)} | Average train f1: {np.mean(f1_list)}'\n",
    "        \n",
    "    else:\n",
    "        msg = f'Epoch: {epoch+1} / {total_epochs} |Iteration: {iteration} / {total_iterations} \\n'\n",
    "        msg += f'Average val loss: {np.mean(loss_list)} | Average val f1: {np.mean(f1_list)}'\n",
    "        \n",
    "    if iteration % print_every == 0:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_TRAIN, x_VAL, y_TRAIN, y_VAL = train_test_split(x_train_padded, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We create a train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(x_TRAIN, y_TRAIN)\n",
    "val_dataset = MyDataset(x_VAL, y_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, num_workers=10, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, num_workers=5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(embedding_matrix)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=0.003, params=model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bbdfa88e9f4e7b9f4c2654fef37d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4082), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 5 |Iteration: 0 / 4082 \n",
      "Average train loss: 0.6757609248161316 | Average train f1: 0.0\n",
      "Epoch: 1 / 5 |Iteration: 500 / 4082 \n",
      "Average train loss: 0.15787995373923144 | Average train f1: 0.3066316496186525\n",
      "Epoch: 1 / 5 |Iteration: 1000 / 4082 \n",
      "Average train loss: 0.1416004403614319 | Average train f1: 0.3924587154070072\n",
      "Epoch: 1 / 5 |Iteration: 1500 / 4082 \n",
      "Average train loss: 0.1333219802787628 | Average train f1: 0.43986280368012537\n",
      "Epoch: 1 / 5 |Iteration: 2000 / 4082 \n",
      "Average train loss: 0.1292116065053032 | Average train f1: 0.4688155586934848\n",
      "Epoch: 1 / 5 |Iteration: 2500 / 4082 \n",
      "Average train loss: 0.1264233723646257 | Average train f1: 0.48741091205883674\n",
      "Epoch: 1 / 5 |Iteration: 3000 / 4082 \n",
      "Average train loss: 0.12423817004905427 | Average train f1: 0.5007370534041804\n",
      "Epoch: 1 / 5 |Iteration: 3500 / 4082 \n",
      "Average train loss: 0.12221043556183789 | Average train f1: 0.5128028685193958\n",
      "Epoch: 1 / 5 |Iteration: 4000 / 4082 \n",
      "Average train loss: 0.12103053184318799 | Average train f1: 0.5213153345803362\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 5 |Iteration: 0 / 4082 \n",
      "Average val loss: 0.7146368026733398 | Average val f1: 0.7027027027027027\n",
      "Epoch: 1 / 5 |Iteration: 150 / 4082 \n",
      "Average val loss: 0.7370871309413026 | Average val f1: 0.5879052335906325\n",
      "Epoch: 1 / 5 |Iteration: 300 / 4082 \n",
      "Average val loss: 0.737037448788006 | Average val f1: 0.5946041844971859\n",
      "Epoch: 1 / 5 |Iteration: 450 / 4082 \n",
      "Average val loss: 0.7381745005922677 | Average val f1: 0.5954202538687579\n",
      "Epoch: 1 / 5 |Iteration: 600 / 4082 \n",
      "Average val loss: 0.7381020564207816 | Average val f1: 0.5970251876450733\n",
      "Epoch: 1 / 5 |Iteration: 750 / 4082 \n",
      "Average val loss: 0.7386753028147072 | Average val f1: 0.5984694933433252\n",
      "Epoch: 1 / 5 |Iteration: 900 / 4082 \n",
      "Average val loss: 0.739078609382405 | Average val f1: 0.5982427027903153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4082), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 5 |Iteration: 0 / 4082 \n",
      "Average train loss: 0.10370098054409027 | Average train f1: 0.6896551724137931\n",
      "Epoch: 2 / 5 |Iteration: 500 / 4082 \n",
      "Average train loss: 0.09964284382596938 | Average train f1: 0.6304664008967932\n",
      "Epoch: 2 / 5 |Iteration: 1000 / 4082 \n",
      "Average train loss: 0.10104360485395471 | Average train f1: 0.6277714753125372\n",
      "Epoch: 2 / 5 |Iteration: 1500 / 4082 \n",
      "Average train loss: 0.10142815114060376 | Average train f1: 0.6252338245778297\n",
      "Epoch: 2 / 5 |Iteration: 2000 / 4082 \n",
      "Average train loss: 0.10140279483521121 | Average train f1: 0.62594545393653\n",
      "Epoch: 2 / 5 |Iteration: 2500 / 4082 \n",
      "Average train loss: 0.10137675670696135 | Average train f1: 0.6240606004091878\n",
      "Epoch: 2 / 5 |Iteration: 3000 / 4082 \n",
      "Average train loss: 0.101204032355827 | Average train f1: 0.6251050549437019\n",
      "Epoch: 2 / 5 |Iteration: 3500 / 4082 \n",
      "Average train loss: 0.10134746252605147 | Average train f1: 0.6255418975043548\n",
      "Epoch: 2 / 5 |Iteration: 4000 / 4082 \n",
      "Average train loss: 0.10110747563808418 | Average train f1: 0.6259868998611248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 5 |Iteration: 0 / 4082 \n",
      "Average val loss: 0.6757248044013977 | Average val f1: 0.7804878048780488\n",
      "Epoch: 2 / 5 |Iteration: 150 / 4082 \n",
      "Average val loss: 0.7119232881937595 | Average val f1: 0.6255444906716922\n",
      "Epoch: 2 / 5 |Iteration: 300 / 4082 \n",
      "Average val loss: 0.7118506506827978 | Average val f1: 0.6292593317854295\n",
      "Epoch: 2 / 5 |Iteration: 450 / 4082 \n",
      "Average val loss: 0.7131118125503185 | Average val f1: 0.6317255507908925\n",
      "Epoch: 2 / 5 |Iteration: 600 / 4082 \n",
      "Average val loss: 0.7130371877635379 | Average val f1: 0.6325364574564193\n",
      "Epoch: 2 / 5 |Iteration: 750 / 4082 \n",
      "Average val loss: 0.7135759479355082 | Average val f1: 0.631953271102875\n",
      "Epoch: 2 / 5 |Iteration: 900 / 4082 \n",
      "Average val loss: 0.7138687058638257 | Average val f1: 0.6312170755667168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4082), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 5 |Iteration: 0 / 4082 \n",
      "Average train loss: 0.08977300673723221 | Average train f1: 0.75\n",
      "Epoch: 3 / 5 |Iteration: 500 / 4082 \n",
      "Average train loss: 0.09029924408523385 | Average train f1: 0.6769945379463668\n",
      "Epoch: 3 / 5 |Iteration: 1000 / 4082 \n",
      "Average train loss: 0.09073308476811641 | Average train f1: 0.6782732664774398\n",
      "Epoch: 3 / 5 |Iteration: 1500 / 4082 \n",
      "Average train loss: 0.09136935360456688 | Average train f1: 0.6759080023645861\n",
      "Epoch: 3 / 5 |Iteration: 2000 / 4082 \n",
      "Average train loss: 0.09189793464729096 | Average train f1: 0.6729967617068586\n",
      "Epoch: 3 / 5 |Iteration: 2500 / 4082 \n",
      "Average train loss: 0.09221101431001048 | Average train f1: 0.6697464731490493\n",
      "Epoch: 3 / 5 |Iteration: 3000 / 4082 \n",
      "Average train loss: 0.09275128697353933 | Average train f1: 0.6665690210367503\n",
      "Epoch: 3 / 5 |Iteration: 3500 / 4082 \n",
      "Average train loss: 0.09298093200381127 | Average train f1: 0.665323816469845\n",
      "Epoch: 3 / 5 |Iteration: 4000 / 4082 \n",
      "Average train loss: 0.09329256323282345 | Average train f1: 0.6636361133677301\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 5 |Iteration: 0 / 4082 \n",
      "Average val loss: 0.7284998297691345 | Average val f1: 0.6250000000000001\n",
      "Epoch: 3 / 5 |Iteration: 150 / 4082 \n",
      "Average val loss: 0.7495720110192204 | Average val f1: 0.559860164170099\n",
      "Epoch: 3 / 5 |Iteration: 300 / 4082 \n",
      "Average val loss: 0.7483534383219342 | Average val f1: 0.5633200636543532\n",
      "Epoch: 3 / 5 |Iteration: 450 / 4082 \n",
      "Average val loss: 0.7500426896131224 | Average val f1: 0.565583650260447\n",
      "Epoch: 3 / 5 |Iteration: 600 / 4082 \n",
      "Average val loss: 0.7496208790534744 | Average val f1: 0.5673715692800083\n",
      "Epoch: 3 / 5 |Iteration: 750 / 4082 \n",
      "Average val loss: 0.7499592608999158 | Average val f1: 0.5698167434269689\n",
      "Epoch: 3 / 5 |Iteration: 900 / 4082 \n",
      "Average val loss: 0.7503141975826216 | Average val f1: 0.5706872815571655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4082), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / 5 |Iteration: 0 / 4082 \n",
      "Average train loss: 0.08603644371032715 | Average train f1: 0.5\n",
      "Epoch: 4 / 5 |Iteration: 500 / 4082 \n",
      "Average train loss: 0.08593049907532638 | Average train f1: 0.6979684627607862\n",
      "Epoch: 4 / 5 |Iteration: 1000 / 4082 \n",
      "Average train loss: 0.08599962853453495 | Average train f1: 0.6996540570957894\n",
      "Epoch: 4 / 5 |Iteration: 1500 / 4082 \n",
      "Average train loss: 0.086021215210034 | Average train f1: 0.6984576175536356\n",
      "Epoch: 4 / 5 |Iteration: 2000 / 4082 \n",
      "Average train loss: 0.08605017085307869 | Average train f1: 0.6948429054506239\n",
      "Epoch: 4 / 5 |Iteration: 2500 / 4082 \n",
      "Average train loss: 0.08624610503162088 | Average train f1: 0.6932624751650064\n",
      "Epoch: 4 / 5 |Iteration: 3000 / 4082 \n",
      "Average train loss: 0.08671071162457884 | Average train f1: 0.691433510708195\n",
      "Epoch: 4 / 5 |Iteration: 3500 / 4082 \n",
      "Average train loss: 0.08748055732059108 | Average train f1: 0.6887314710816316\n",
      "Epoch: 4 / 5 |Iteration: 4000 / 4082 \n",
      "Average train loss: 0.08760272579952437 | Average train f1: 0.6880276558411972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / 5 |Iteration: 0 / 4082 \n",
      "Average val loss: 0.7127043604850769 | Average val f1: 0.7368421052631577\n",
      "Epoch: 4 / 5 |Iteration: 150 / 4082 \n",
      "Average val loss: 0.7430671094269152 | Average val f1: 0.5633952284581831\n",
      "Epoch: 4 / 5 |Iteration: 300 / 4082 \n",
      "Average val loss: 0.7425184988500272 | Average val f1: 0.57068513921754\n",
      "Epoch: 4 / 5 |Iteration: 450 / 4082 \n",
      "Average val loss: 0.7442796235602606 | Average val f1: 0.5753951705845506\n",
      "Epoch: 4 / 5 |Iteration: 600 / 4082 \n",
      "Average val loss: 0.7439240895571209 | Average val f1: 0.576377032711644\n",
      "Epoch: 4 / 5 |Iteration: 750 / 4082 \n",
      "Average val loss: 0.7442886838106595 | Average val f1: 0.578875160532157\n",
      "Epoch: 4 / 5 |Iteration: 900 / 4082 \n",
      "Average val loss: 0.7446724934530311 | Average val f1: 0.5806434352219765\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4082), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / 5 |Iteration: 0 / 4082 \n",
      "Average train loss: 0.07943730056285858 | Average train f1: 0.6206896551724137\n",
      "Epoch: 5 / 5 |Iteration: 500 / 4082 \n",
      "Average train loss: 0.08043031132744696 | Average train f1: 0.7197106377008222\n",
      "Epoch: 5 / 5 |Iteration: 1000 / 4082 \n",
      "Average train loss: 0.08132212616495796 | Average train f1: 0.720088445027162\n",
      "Epoch: 5 / 5 |Iteration: 1500 / 4082 \n",
      "Average train loss: 0.08131135880033784 | Average train f1: 0.7192394434395784\n",
      "Epoch: 5 / 5 |Iteration: 2000 / 4082 \n",
      "Average train loss: 0.08184458019452981 | Average train f1: 0.7160404314533206\n",
      "Epoch: 5 / 5 |Iteration: 2500 / 4082 \n",
      "Average train loss: 0.0820724282991655 | Average train f1: 0.7147455709779477\n",
      "Epoch: 5 / 5 |Iteration: 3000 / 4082 \n",
      "Average train loss: 0.08240269584490016 | Average train f1: 0.7102570564699858\n",
      "Epoch: 5 / 5 |Iteration: 3500 / 4082 \n",
      "Average train loss: 0.08282423328785973 | Average train f1: 0.7087626647349291\n",
      "Epoch: 5 / 5 |Iteration: 4000 / 4082 \n",
      "Average train loss: 0.08321584154863607 | Average train f1: 0.7072706387375507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / 5 |Iteration: 0 / 4082 \n",
      "Average val loss: 0.6966636180877686 | Average val f1: 0.7567567567567567\n",
      "Epoch: 5 / 5 |Iteration: 150 / 4082 \n",
      "Average val loss: 0.7320115929407789 | Average val f1: 0.5843491030975664\n",
      "Epoch: 5 / 5 |Iteration: 300 / 4082 \n",
      "Average val loss: 0.7314662466017511 | Average val f1: 0.5901286834300182\n",
      "Epoch: 5 / 5 |Iteration: 450 / 4082 \n",
      "Average val loss: 0.7335175245405565 | Average val f1: 0.5904170187713422\n",
      "Epoch: 5 / 5 |Iteration: 600 / 4082 \n",
      "Average val loss: 0.7334974830638549 | Average val f1: 0.5884888052357228\n",
      "Epoch: 5 / 5 |Iteration: 750 / 4082 \n",
      "Average val loss: 0.7336311599862242 | Average val f1: 0.5898495219256594\n",
      "Epoch: 5 / 5 |Iteration: 900 / 4082 \n",
      "Average val loss: 0.7340013038834244 | Average val f1: 0.5895182676345565\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "print_every_train = 500\n",
    "print_every_val = 150\n",
    "\n",
    "\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    \n",
    "    # train model\n",
    "    \n",
    "    f1_scores_train = []\n",
    "    losses_train = []\n",
    "\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(tqdm_notebook(train_loader, leave=False, total=len(train_loader))):\n",
    "        \n",
    "        # pass batches to GPU\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute predictions: forward pass on the batch\n",
    "        preds = model.forward(x)\n",
    "        \n",
    "        # compute the loss on the batch\n",
    "        loss = criterion(preds, y)\n",
    "        \n",
    "        # compute the gardients by derivating the loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of losses and f1 scores for each epoch\n",
    "        losses_train.append(loss.item())\n",
    "        \n",
    "        f1_score_train = compute_f1_score(y, preds)\n",
    "        f1_scores_train.append(f1_score_train)\n",
    "        \n",
    "        # print metrics\n",
    "        print_metrics(i, len(train_loader), epoch, num_epochs, losses_train, f1_scores_train, print_every_train)\n",
    "        \n",
    "    # evaluation mode\n",
    "        \n",
    "    f1_scores_val = []\n",
    "    losses_val = []\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (x, y) in enumerate(tqdm_notebook(val_loader, leave=False, total=len(val_loader))):\n",
    "        \n",
    "        # pass batches to GPU\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        # make predictions\n",
    "        preds = model.forward(x)\n",
    "        \n",
    "        # computes the losses and f1 scores\n",
    "        loss = criterion(y, preds)\n",
    "        losses_val.append(loss.item())\n",
    "        \n",
    "        f1_score_val = compute_f1_score(y, preds)\n",
    "        f1_scores_val.append(f1_score_val)\n",
    "        \n",
    "        # print metrics\n",
    "        print_metrics(i, len(train_loader), epoch, num_epochs, losses_val, f1_scores_val, print_every_val, train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
